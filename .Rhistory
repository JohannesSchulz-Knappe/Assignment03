sa2$eligible.voters <- NULL
sa2$voters.n        <- NULL
sa2$valid.votes     <- NULL
sa2$CDU.n           <- NULL
sa2$Linke.n         <- NULL
sa2$SPD.n           <- NULL
sa2$Greens.n        <- NULL
sa2$FDP.n           <- NULL
# Step 3: Merge variables into one dataframe
sa <- merge(sa1, sa2, c("ID", "district.name"))
# clean district names
sa$district.name <- gsub(pattern = 'Landkreis ',
replacement = '',
x = sa$district.name)
sa$district.name <- gsub(pattern = 'Kreisfreie Stadt ',
replacement = '',
x = sa$district.name)
# Step 4: Adding state and year variable
sa$state <- "SA"
sa$election.year <- "2016"
#---------------------------#
# Merge election data       #
#---------------------------#
data.election <- rbind(bw, rp, sa) # merge all election data sets into one data frame
# replace commas with periods
data.election[, c(4:10)] <- as.numeric(gsub(",", ".", as.matrix(data.election[, c(4:10)])))
# round to 2 digits
data.election[, c(4:10)] <- round(as.matrix(data.election[, c(4:10)]), digits=2)
data.election$ID <- as.numeric(as.character(data.election$ID)) # convert ID into numeric
# convert ID into numeric
data.election$election.year <- as.numeric(data.election$election.year)
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Merging Final Dataset
# Johannes Schulz-Knappe
# Update 25 April 2016
# Hertie School of Governance
#######################################################################
rm(list = ls())
library(repmis)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
# Running the gathering and cleaning files
# 1. Electoral data gathering
source("election_data_gathering.R")
# 2. Structural data gathering
source("structural_data_gathering.R")
# 3. Electoral data cleaning
source("election_data_cleaning.R")
# 4. Structural data cleaning
source("structural_data_cleaning.R")
# Merging the data
Data <- merge(data.election, edu, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, refugee, "ID")
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Election Data Gathering
# Md Mujahedul Islam & Johannes Schulz-Knappe
# Update 24 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# Preparation                             #
#-----------------------------------------#
## if not done before, install packages:
# install.packages("repmis")
library(repmis)
library(rvest)
library(dplyr)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
#-------------------------------------------#
# Retrieve the data for the state elections #
#-------------------------------------------#
# All downloads updated at 24.04.2016
### Baden-Württemberg 2016 & 2011
URL <- 'http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/02035000.tab?E=KR'
webpage <- read_html(URL)
table <- html_nodes(webpage, 'table')
bw_raw <- html_table(table, header = FALSE,
fill = TRUE)
bw_raw <- as.data.frame(bw_raw) # get and parse table from webpage
bw_raw$X1 <- repair_encoding(bw_raw$X1) # repair encoding of first column
rm(URL)
rm(webpage)
rm(table) # clean environment
### Rhineland-Palatinate 2016
rp16_raw <- read.csv('http://www.wahlen.rlp.de/ltw/wahlen/2016/downloads/lw000.txt',
sep = ';', header = TRUE)
### Rhineland-Palatinate 2011 (Landkreise)
rp11_raw <- read.csv('http://www.wahlen.rlp.de/ltw/wahlen/2011/downloads/lw000.txt',
sep = ';', header = TRUE)
### Saxony Anhalt 2016
sa16_raw <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
### Saxony Anhalt 2011
sa11_raw <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt11/erg/csv/lt11dat2.csv',
sep = ';')
#------------------------------------------------------#
# Retrieve the data for the additional state elections #
#------------------------------------------------------#
# Attention:
# Since the data of different states is very diverse, we focus on the data of
# the last three state elections (bw16, rp16, sa16) first
# Bremen 2015
# Hamburg 2015
# Brandenburg 2014
# bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
# 2, cache = TRUE)
## SHA-1 hash of the downloaded data file is: 'd017e1c2b9bf28227362978e41986a023f149237'
# Saxony 2014
# Thuringia 2014
# Hesse 2013
## data available in compressed format
# Store the URL in an object called 'URL'
# URL <- "http://www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
# temp <- tempfile() # create a temporary file
# download.file(URL, temp) # download compressed file into the temporary file
# he13 <- import(gzfile(temp, "landtagswahl2013.xls")) # Decompress the file and
# convert it into a data frame (not working)
# unlink(temp) # delete the temporary file
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Election Data Gathering
# Md Mujahedul Islam & Johannes Schulz-Knappe
# Update 24 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# Preparation                             #
#-----------------------------------------#
## if not done before, install packages:
# install.packages("repmis")
rm(list = ls())
library(repmis)
library(rvest)
library(dplyr)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
#-------------------------------------------#
# Retrieve the data for the state elections #
#-------------------------------------------#
# All downloads updated at 24.04.2016
### Baden-Württemberg 2016 & 2011
URL <- 'http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/02035000.tab?E=KR'
webpage <- read_html(URL)
table <- html_nodes(webpage, 'table')
bw_raw <- html_table(table, header = FALSE,
fill = TRUE)
bw_raw <- as.data.frame(bw_raw) # get and parse table from webpage
bw_raw$X1 <- repair_encoding(bw_raw$X1) # repair encoding of first column
rm(URL)
rm(webpage)
rm(table) # clean environment
### Rhineland-Palatinate 2016
rp16_raw <- read.csv('http://www.wahlen.rlp.de/ltw/wahlen/2016/downloads/lw000.txt',
sep = ';', header = TRUE)
### Rhineland-Palatinate 2011 (Landkreise)
rp11_raw <- read.csv('http://www.wahlen.rlp.de/ltw/wahlen/2011/downloads/lw000.txt',
sep = ';', header = TRUE)
### Saxony Anhalt 2016
sa16_raw <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
### Saxony Anhalt 2011
sa11_raw <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt11/erg/csv/lt11dat2.csv',
sep = ';')
#------------------------------------------------------#
# Retrieve the data for the additional state elections #
#------------------------------------------------------#
# Attention:
# Since the data of different states is very diverse, we focus on the data of
# the last three state elections (bw16, rp16, sa16) first
# Bremen 2015
# Hamburg 2015
# Brandenburg 2014
# bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
# 2, cache = TRUE)
## SHA-1 hash of the downloaded data file is: 'd017e1c2b9bf28227362978e41986a023f149237'
# Saxony 2014
# Thuringia 2014
# Hesse 2013
## data available in compressed format
# Store the URL in an object called 'URL'
# URL <- "http://www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
# temp <- tempfile() # create a temporary file
# download.file(URL, temp) # download compressed file into the temporary file
# he13 <- import(gzfile(temp, "landtagswahl2013.xls")) # Decompress the file and
# convert it into a data frame (not working)
# unlink(temp) # delete the temporary file
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Structural Data Gathering
# Johannes Schulz-Knappe
# Update 24 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# Preparation                             #
#-----------------------------------------#
## if not done before, install packages:
# install.packages("repmis")
# install.packages("rio")
# install.packages("xlsx")
# Library packages
library(repmis)
library(rio)
library(xlsx)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
#-------------------------------------------#
# Retrieve structura data                   #
#-------------------------------------------#
### Attention:
# Since the DESTATIS webpage is down, we currently use data of another group that used similar
# data in their project last term. This will be updated as soon as the service of the DESTATIS
# webpage is available again
### Citation:
# Data has to be downloaded manually, as the federal statistical offices
# (DeStatis/Genesis) does not provide an API for free. Two sources are used:
# https://www-genesis.destatis.de/genesis/online and
# https://www.regionalstatistik.de/genesis/online (specified for each variable).
# All data sets on those platforms are attributed a certain table number,
# which is provided in the sections below. Finding the files works best when
# inserting the table number into the search box at the beginning of the
# respective pages.
# For some data sets a certain time frame has to be specified. If we have done so,
# it is described in the sections below.
# All downloaded data is downloaded as a csv file and saved in the folder Data/Indepdendent Variables.
# No changes have been made to the files before loading them into R.
# Note: the table number and the file name are identical.
### Citation end
# Education
# Table AI003-2 from https://www.regionalstatistik.de/genesis/online
# Downloaded on 11/8/2015
# Specification: "Zeit auswählen" (select time) = 2013
edu_raw <- read.csv("Data_Files/AI003-2.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
col.names = c("date", "district.ID", "district.name",
"abitur.percent", "nodegree.percent"),
skip = 6,
nrows = 525,
dec=",") # loads data frame
# Unemployment rate
# Table 659-71-4 from https://www.regionalstatistik.de/genesis/online
# Downloaded 11/8/2015
# Specification: "Zeit auswählen" (select time) = 2014
unemp_raw <- read.csv("Data_Files/659-71-4.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
nrows = 533,
dec = ",") # loads data frame
# GDP/capita
# Table AI-N-10 from https://www.regionalstatistik.de/genesis/online
# Downloaded 11/8/2015
# Specification: "Zeit auswählen" (select time) = 2012
gdp_raw <- read.csv("Data_Files/AI-N-10.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
col.names = c("date", "district.ID", "district.name", "GDP.cap"),
skip = 7,
nrows = 525) # loads data frame
# number of refugees
# Table 661-31-4 from https://www.regionalstatistik.de/genesis/online
# Downloaded 11/8/2015
# Specification: "Zeit auswählen" (select time) = 12/31/2013
refugee_raw <- read.csv("Data_Files/661-31-4.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
col.names = c("date", "district.ID", "district.name",
"column04", "column05", "column06",
"column07", "column08", "column09",
"asylum.seeker"),
skip = 9,
nrows = 525,
dec = ",") # loads data frame
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Election Data Cleaning
# Md Mujahedul Islam & Johannes Schulz-Knappe
# Update 25 April 2016
# Hertie School of Governance
#######################################################################
#--------------------------------------#
# Preparation                          #
#--------------------------------------#
## if not done before, install packages:
# install.packages(plyr)
library("plyr")
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # delete possible_dir
#------------------#
# Cleaning data    #
#------------------#
### 1. Baden-Württemberg
# Step 1: Extract dependent variable for 2016
bw1 <- bw_raw[, c(1, 2, 9)] # keep relevant columns
names(bw1) <- c("district.name", "election.year", "vote.AfD") # rename columns
bw1 <- bw1[-c(1, 2, 3, 3+2*(1:44)), ] # delete rows that are not 2016
# Step 2: Extract non-voters and other party voteshares for 2011
bw2 <- bw_raw[, c(1, 3, 4, 5, 6, 7, 8)] # keep relevant columns
names(bw2) <- c("district.name", "lag.turnout", "lag.CDU", "lag.Greens",
"lag.SPD", "lag.FDP", "lag.Linke") # rename columns
bw2 <- bw2[-c(1, 2, 3, 4, 4+2*(1:43)), ] # delete rows that are not 2011
bw2$district.name <- bw1$district.name # add district.names as identifier
# Step 3: Merge variables into one dataframe
bw <- merge(bw1, bw2, "district.name")
# Step 4: Adding state variable
bw$state <- "BW"
# Step 5: Create district ID
bw_ID <- refugee_raw[, c(2, 3)] # Retrieve ID from refugee_raw
bw_ID <- bw_ID[c(207:219, 221:232, 234:243, 245:253), ] # keep district IDs for BW
# Manipulate district names to match bw1 & bw2 district names
bw_ID$district.name <- gsub(pattern = 'Heilbronn, Landkreis',
replacement = 'Heilbronn (Land)',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = 'Karlsruhe, Landkreis',
replacement = 'Karlsruhe (Land)',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = 'Heilbronn, Kreisfreie Stadt',
replacement = 'Heilbronn (Stadt)',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = 'Karlsruhe, Kreisfreie Stadt',
replacement = 'Karlsruhe (Stadt)',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = ', Landkreis',
replacement = '',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = ', Kreisfreie Stadt',
replacement = '',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = ', Universitätsstadt',
replacement = '',
x = bw_ID$district.name)
bw_ID$district.name <- gsub(pattern = ', Landeshauptstadt',
replacement = '',
x = bw_ID$district.name)
bw_ID <- arrange(bw_ID, bw_ID$district.name) # sort alphabetically
bw$ID <- bw_ID$district.ID # add ID to bw
bw <- bw[c(11, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)] # reorder columns
### 2. Rhineland-Palatinate
# Step 1: Extract dependent variable for 2016
rp1 <- rp16_raw[, c(2, 105)] # keep relevant columns
names(rp1) <- c("district.name", "vote.AfD") # rename columns
rp1 <- rp1[-c(1, grep('VG$', rp1$district.name)), ] # delete rows that are not district level
# clean district names
rp1$district.name <- gsub(pattern = 'Kaiserslautern, Landkreis',
replacement = 'Kaiserslautern (Land)',
x = rp1$district.name)
rp1$district.name <- gsub(pattern = 'Kaiserslautern, Kreisfreie Stadt',
replacement = 'Kaiserslautern (Stadt)',
x = rp1$district.name)
rp1$district.name <- gsub(pattern = ', Landkreis',
replacement = '',
x = rp1$district.name)
rp1$district.name <- gsub(pattern = ', Kreisfreie Stadt',
replacement = '',
x = rp1$district.name)
# Step 2: Extract non-voters and other party voteshares for 2011
rp2 <- rp11_raw[, c(2, 9, 94, 95, 96, 97, 98)] # keep relevant columns
names(rp2) <- c("district.name", "lag.turnout", "lag.SPD",
"lag.CDU", "lag.FDP", "lag.Greens", "lag.Linke") # rename columns
rp2 <- rp2[-1, ] # delete rows that are not district level
# clean district names
rp2$district.name <- gsub(pattern = 'Kaiserslautern, Landkreis',
replacement = 'Kaiserslautern (Land)',
x = rp2$district.name)
rp2$district.name <- gsub(pattern = 'Kaiserslautern, Kreisfreie Stadt',
replacement = 'Kaiserslautern (Stadt)',
x = rp2$district.name)
rp2$district.name <- gsub(pattern = ', Landkreis',
replacement = '',
x = rp2$district.name)
rp2$district.name <- gsub(pattern = ', Kreisfreie Stadt',
replacement = '',
x = rp2$district.name)
# Step 3: Merge variables into one dataframe
rp <- merge(rp1, rp2, "district.name")
# Step 4: Adding state and year variable
rp$state <- "RP"
rp$election.year <- "2016"
# Step 5: Create district ID
rp_ID <- refugee_raw[, c(2, 3)] # Retrieve ID from refugee_raw
rp_ID <- rp_ID[c(grep('^07', rp_ID$district.ID)), ] # keep IDs for RP
rp_ID <- rp_ID[-c(1, 2, 14, 20), ] # keep IDs on district level
# clean district names
rp_ID$district.name <- gsub(pattern = 'Kaiserslautern, Landkreis',
replacement = 'Kaiserslautern (Land)',
x = rp_ID$district.name)
rp_ID$district.name <- gsub(pattern = 'Kaiserslautern, Kreisfreie Stadt',
replacement = 'Kaiserslautern (Stadt)',
x = rp_ID$district.name)
rp_ID$district.name <- gsub(pattern = ', Landkreis',
replacement = '',
x = rp_ID$district.name)
rp_ID$district.name <- gsub(pattern = ', Kreisfreie Stadt',
replacement = '',
x = rp_ID$district.name)
rp_ID <- arrange(rp_ID, rp_ID$district.name) # sort alphabetically
rp$ID <- rp_ID$district.ID # add ID to rp
rp <- rp[c(11, 1, 10, 2, 3, 4, 5, 6, 7, 8, 9)] # reorder columns
### 3. Saxony Anhalt
# Step 1: Extract dependent variable for 2016
sa1 <- sa16_raw[, c(7, 8, 12, 19)] # keep relevant columns
names(sa1) <- c("ID", "district.name", "valid.votes", "AfD.n") # rename columns
sa1 <- sa1[-c(1, 16:58), ] # delete rows that are not district level
sa1$vote.AfD    <- sa1$AfD.n/sa1$valid.votes*100
sa1$AfD.n       <- NULL
sa1$valid.votes <- NULL # Calculate voteshare variable and delete used columns
# Step 2: Extract non-voters and other party voteshares for 2011
sa2 <- sa11_raw[, c(7, 8, 9, 10, 12, 13, 14, 15, 16, 22)] # keep relevant columns
names(sa2) <- c("ID", "district.name", "eligible.voters", "voters.n",
"valid.votes", "CDU.n", "Linke.n", "SPD.n", "Greens.n", "FDP.n")
# rename columns
sa2 <- sa2[-c(1, 16:60), ] # delete rows that are not district level
# calculating voter turnout
sa2$lag.turnout <- sa2$voters.n/sa2$eligible.voters*100
# calculating party vote shares in percentage
sa2$lag.CDU     <- sa2$CDU.n/sa2$voters.n*100
sa2$lag.Linke   <- sa2$Linke.n/sa2$voters.n*100
sa2$lag.SPD     <- sa2$SPD.n/sa2$voters.n*100
sa2$lag.Greens  <- sa2$Greens.n/sa2$voters.n*100
sa2$lag.FDP     <- sa2$FDP.n/sa2$voters.n*100
# deleting used columns
sa2$eligible.voters <- NULL
sa2$voters.n        <- NULL
sa2$valid.votes     <- NULL
sa2$CDU.n           <- NULL
sa2$Linke.n         <- NULL
sa2$SPD.n           <- NULL
sa2$Greens.n        <- NULL
sa2$FDP.n           <- NULL
# Step 3: Merge variables into one dataframe
sa <- merge(sa1, sa2, c("ID", "district.name"))
# clean district names
sa$district.name <- gsub(pattern = 'Landkreis ',
replacement = '',
x = sa$district.name)
sa$district.name <- gsub(pattern = 'Kreisfreie Stadt ',
replacement = '',
x = sa$district.name)
# Step 4: Adding state and year variable
sa$state <- "SA"
sa$election.year <- "2016"
#---------------------------#
# Merge election data       #
#---------------------------#
data.election <- rbind(bw, rp, sa) # merge all election data sets into one data frame
# replace commas with periods
data.election[, c(4:10)] <- as.numeric(gsub(",", ".", as.matrix(data.election[, c(4:10)])))
# round to 2 digits
data.election[, c(4:10)] <- round(as.matrix(data.election[, c(4:10)]), digits=2)
data.election$ID <- as.numeric(as.character(data.election$ID)) # convert ID into numeric
# convert ID into numeric
data.election$election.year <- as.numeric(data.election$election.year)
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Merging Final Dataset
# Johannes Schulz-Knappe
# Update 25 April 2016
# Hertie School of Governance
#######################################################################
rm(list = ls())
library(repmis)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
# Running the gathering and cleaning files
# 1. Electoral data gathering
source("election_data_gathering.R")
# 2. Structural data gathering
source("structural_data_gathering.R")
# 3. Electoral data cleaning
source("election_data_cleaning.R")
# 4. Structural data cleaning
source("structural_data_cleaning.R")
# Merging the data
Data <- merge(data.election, edu, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, refugee, "ID")
load("~/GitHub/Assignment03/.RData")
View(Data)
