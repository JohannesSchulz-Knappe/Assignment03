govqual <- read.table('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
library(import)
library(rio)
install.packages(rio)
install.packages('rio')
library(rio)
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(list = ls()) #just to clear all
install.packages("dplyr")
install.packages("magrittr")
install.packages("readstata13")
install.packages("ggplot2")
install.packages("reshape")
install.packages("plyr")
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(load, loaded)
data(USArrests) # to load the data
names(USArrests) # to see names of variables
dim(USArrests) # to see how big the data frame, for instance, it has 50 rows, 4 variables
arrange(USArrests, murder) # to arrage data to see at a glance which state has highest murder rate
arrange(USArrests, Murder) # to arrage data to see at a glance which state has highest murder rate
attributes(USArrests)
attributes(USArrests)$row.names
attributes(USArrests)
USArrests <- rename(USArrests, c(Assault  = "assault",
Murder   = "murder",
UrbanPop = "urbanpop",
Rape     = "rape"))
USArrests$states <- row.names(USArrests)  # creating "states"
USArrests$states <- row.names(USArrests)  # creating "states" variable
USArrests <- USArrests[, c(5,1:4)]
View(USArrests)
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
mean() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
View(i)
i
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
median() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
mean(USArrests$murder, na.rm = TRUE)
mean(USArrests$assault, na.rm = TRUE)
mean(USArrests$urbanpop, na.rm = TRUE)
mean(USArrests$rape, na.rm = TRUE)
median(USArrests$murder, na.rm = TRUE)
median(USArrests$assault, na.rm = TRUE)
median(USArrests$urbanpop, na.rm = TRUE)
median(USArrests$rape, na.rm = TRUE)
range(USArrests$murder)
range(USArrests$assault)
range(USArrests$urbanpop)
range(USArrests$rape)
summary(USArrests$murder, assault, urbanpop, rape)
summary(USArrests)
summary(USArrests)
ggplot(USArrests) +
geom_bar(aes(y = murder, x = reorder(states, -murder)),
stat = "identity") +
ylab("Murder Rate per 100,000") +
xlab("State") +
ggtitle("Murder Rate in the United States in 1973") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_histogram(aes(x = urbanpop),
colour = "black",
fill = "transparent",
binwidth = 2) +
ylab("Frequency") +
xlab("Population in % living in urban areas") +
theme_bw()
states <- row.names(USArrests)
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -Murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States'
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)')
library(dplyr)
library(rvest)
install.packages('rvest')
library(rvest)
URL <- http://www.bbc.com/sport/winter-olympics/2014/medals/countries
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
# Get and parse expenses_table from the webpage
MedalTable <- URL %>% read_html() %>%
html_nodes('#medals-table') %>%
html_table() %>%
as.data.frame
View(MedalTable)
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
rm(list = ls())
library(dplyr)
library(rvest)
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table') %>%
html_table() %>%
as.data.frame
html_nodes('#medals__table') %>%
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__total--silver') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#table') %>%
html_table() %>%
as.data.frame
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
head(MedalsTable)
drop(NA.$MedalsTable)
drop(MedalsTable$NA.)
head(MedalsTable)
MedalsTable$NA. <- NULL
head(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
head(MedalsTable)
View(MedalsTable)
MedalsTable$NA. <- NULL
View(MedalsTable)
TotalMedals <- arrange(MedalsTable, desc(Total))
head(TotalMedals)
tables <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table()
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment02',
'C:/Users/User/Documents/GitHub/Assignment02')
toBibtex(citation())
rm(list = ls())
library(repmis)
library(rio)
library(xlsx)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
rm(possible_dir)
bw16 <- read.csv('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv',
sep = ';')
View(bw16)
rp16a <- read.csv('wahlnachtanalyse-lw2016_page_64.csv', header = FALSE, sep = ';')
rp16b <- read.csv('wahlnachtanalyse-lw2016_page_65.csv', header = FALSE, sep = ';')
View(rp16a)
sa16 <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
2, cache = TRUE)
View(bb14)
URL <- "http://www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
temp <- tempfile()
download.file(URL, temp)
he13 <- read.xlsx(unz(temp, "landtagswahl2013.xls", sheetIndex = 1))
he13 <- read.xlsx(unz(temp, "landtagswahl2013.xls", sheetName = "Gemeinden"))
he13 <- import(unz(temp, "landtagswahl2013.xls"))
he13 <- import(gzfile(temp, "landtagswahl2013.xls"))
he URL in an object called 'URL'
URL <- "http://www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
# Create a temporary file called 'temp' to put the zip file into
temp <- tempfile()
# Download the compressed file into the temporary file
download.file(URL, temp)
# Decompress the file and convert it into a data frame
he13 <- import(gzfile(temp, "landtagswahl2013.xls"))
#-----------------------------------------#
# Preparation                             #
#-----------------------------------------#
# Clear enviornment
rm(list = ls())
# Install packages
## if not done before, install:
# install.packages("repmis")
# install.packages("rio")
# install.packages("xlsx")
library(repmis)
library(rio)
library(xlsx)
# Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
rm(possible_dir)
#-------------------------------------------#
install.packages("xlsx")
install.packages("xlsx")
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Structural Data Gathering
# Johannes Schulz-Knappe
# Updated 23 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# Preparation                             #
#-----------------------------------------#
rm(list = ls()) # Clear enviornment
## if not done before, install packages:
# install.packages("repmis")
# install.packages("rio")
# install.packages("xlsx")
# Library packages
library(repmis)
library(rio)
library(xlsx)
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
set_valid_wd(possible_dir) # Set to first valid directory in the possible_dir vector
rm(possible_dir) # remove possible_dir vector
#-------------------------------------------#
# Retrieve structura data                   #
#-------------------------------------------#
education_raw <- read.csv("Data_Files/AI003-2.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
col.names = c("year", "district.ID", "district.name", "abitur.ratio", "nodegree.ratio"),
skip = 6,
nrows = 525,
dec=",") # loads data frame
View(education_raw)
unemployment_raw <- read.csv("Data_Files/659-71-4.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
nrows = 533,
dec = ",") # loads data frame
View(unemployment_raw)
gdp_raw <- read.csv("Data_Files/AI-N-10.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
col.names = c("year", "district.ID", "district.name", "GDP.cap"),
skip = 7,
nrows = 525) # loads data frame
View(gdp_raw)
refugees_raw <- read.csv("Data_Files/661-31-4.csv",
header = FALSE,
sep = ";",
na.strings = c("-","."),
nrows = 534,
dec = ",") # loads data frame
View(refugees_raw)
bw16 <- read.csv('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv',
sep = ';')
View(bw16)
