govqual <- read.table('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
library(import)
library(rio)
install.packages(rio)
install.packages('rio')
library(rio)
govqual <- import('http://www.qogdata.pol.gu.se/data/qog_std_ts_jan16.csv')
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(list = ls()) #just to clear all
install.packages("dplyr")
install.packages("magrittr")
install.packages("readstata13")
install.packages("ggplot2")
install.packages("reshape")
install.packages("plyr")
install.packages("repmis")
load <- c("dplyr", "magrittr", "readstata13", "ggplot2", "reshape",
"plyr", "repmis")
loaded <- lapply(load, require, character.only = T)
rm(load, loaded)
data(USArrests) # to load the data
names(USArrests) # to see names of variables
dim(USArrests) # to see how big the data frame, for instance, it has 50 rows, 4 variables
arrange(USArrests, murder) # to arrage data to see at a glance which state has highest murder rate
arrange(USArrests, Murder) # to arrage data to see at a glance which state has highest murder rate
attributes(USArrests)
attributes(USArrests)$row.names
attributes(USArrests)
USArrests <- rename(USArrests, c(Assault  = "assault",
Murder   = "murder",
UrbanPop = "urbanpop",
Rape     = "rape"))
USArrests$states <- row.names(USArrests)  # creating "states"
USArrests$states <- row.names(USArrests)  # creating "states" variable
USArrests <- USArrests[, c(5,1:4)]
View(USArrests)
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
mean() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
View(i)
i
for (i in 1:length(names(USArrests))) {
USArrests[, i] %>%
median() %>%
round(digits = 3) %>%
paste(names(USArrests)[i], ., '\n') %>%
cat()
}
mean(USArrests$murder, na.rm = TRUE)
mean(USArrests$assault, na.rm = TRUE)
mean(USArrests$urbanpop, na.rm = TRUE)
mean(USArrests$rape, na.rm = TRUE)
median(USArrests$murder, na.rm = TRUE)
median(USArrests$assault, na.rm = TRUE)
median(USArrests$urbanpop, na.rm = TRUE)
median(USArrests$rape, na.rm = TRUE)
range(USArrests$murder)
range(USArrests$assault)
range(USArrests$urbanpop)
range(USArrests$rape)
summary(USArrests$murder, assault, urbanpop, rape)
summary(USArrests)
summary(USArrests)
ggplot(USArrests) +
geom_bar(aes(y = murder, x = reorder(states, -murder)),
stat = "identity") +
ylab("Murder Rate per 100,000") +
xlab("State") +
ggtitle("Murder Rate in the United States in 1973") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_bar(aes(y = rape, x = reorder(states, -rape)),
stat = "identity") +
ylab("Rape arrests (per 100,000)") +
xlab("States") +
ggtitle("Rape rate in the United States in 1973") +
theme_bw() +
coord_flip()
ggplot(USArrests) +
geom_histogram(aes(x = urbanpop),
colour = "black",
fill = "transparent",
binwidth = 2) +
ylab("Frequency") +
xlab("Population in % living in urban areas") +
theme_bw()
states <- row.names(USArrests)
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -Murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States'
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)')
library(dplyr)
library(rvest)
install.packages('rvest')
library(rvest)
URL <- http://www.bbc.com/sport/winter-olympics/2014/medals/countries
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
# Get and parse expenses_table from the webpage
MedalTable <- URL %>% read_html() %>%
html_nodes('#medals-table') %>%
html_table() %>%
as.data.frame
View(MedalTable)
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
rm(list = ls())
library(dplyr)
library(rvest)
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table') %>%
html_table() %>%
as.data.frame
html_nodes('#medals__table') %>%
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__total--silver') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#table') %>%
html_table() %>%
as.data.frame
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
head(MedalsTable)
drop(NA.$MedalsTable)
drop(MedalsTable$NA.)
head(MedalsTable)
MedalsTable$NA. <- NULL
head(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
head(MedalsTable)
View(MedalsTable)
MedalsTable$NA. <- NULL
View(MedalsTable)
TotalMedals <- arrange(MedalsTable, desc(Total))
head(TotalMedals)
tables <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table()
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment02',
'C:/Users/User/Documents/GitHub/Assignment02')
toBibtex(citation())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Webscraping the datasets
# Johannes Schulz-Knappe
# Updated 22 April 2016
# Hertie School of Governance
#######################################################################
# Install packages
## if not done before, install:
# install.packages("repmis")
# install.packages("rio")
library(repmis)
library(rio)
# Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
read.table('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv')
bw16 <- import('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv')
View(bw16)
bw16 <- read.csv('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv',
sep = ';')
View(bw16)
URL <- "https://www.statistik.rlp.de/fileadmin/dokumente/nach_themen/stat_analysen/wahlen/lw/wahlnachtanalyse-lw2016.pdf"
# Create a temporary file called 'temp' to put the pdf file into
temp <- tempfile()
# Download the pdf file into the temporary file.
download.file(URL, temp)
zip <- tempfile()
download.file("ftp://ftp.foolabs.com/pub/xpdf/xpdfbin-win-3.03.zip", zip)
exe <- download.file("https://s3.amazonaws.com/bytescout.com/files/PDFMultitool.exe")
exe <- tempfile()
download.file("https://s3.amazonaws.com/bytescout.com/files/PDFMultitool.exe", exe)
View
ls()
rm(list = ls())
library(repmis)
# Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
rm(possible_dir)
bw16 <- read.csv('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv',
sep = ';', cache = TRUE)
bw16 <- read.csv('http://www.statistik.baden-wuerttemberg.de/Wahlen/Landtag/Kreise.csv',
sep = ';')
View(bw16)
read.csv("Assignment03/wahlnachtanalyse-lw2016_page_64.csv")
read.csv("/wahlnachtanalyse-lw2016_page_64.csv")
read.csv("C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03/wahlnachtanalyse-lw2016_page_64.csv")
rp16a <- read.csv("C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03/wahlnachtanalyse-lw2016_page_64.csv")
View(rp16a)
read.csv(/Assignment03/wahlnachtanalyse-lw2016_page_64.csv)
read.csv('/wahlnachtanalyse-lw2016_page_64.csv')
read.csv('/Assignment03/wahlnachtanalyse-lw2016_page_64.csv')
read.csv('Assignment03/wahlnachtanalyse-lw2016_page_65.csv')
getwd
getwd()
rp16b <- read.csv('/wahlnachtanalyse-lw2016_page_65.csv')
list.files()
rp16b <- read.csv('wahlnachtanalyse-lw2016_page_65.csv')
rp16a <- read.csv('wahlnachtanalyse-lw2016_page_64.csv', sep = ';')
rp16b <- read.csv('wahlnachtanalyse-lw2016_page_65.csv', sep = ';')
View(rp16a)
rp16a <- read.csv('wahlnachtanalyse-lw2016_page_64.csv', header = FALSE, sep = ';')
rp16b <- read.csv('wahlnachtanalyse-lw2016_page_65.csv', header = FALSE, sep = ';')
View(rp16a)
View(rp16b)
sa16 <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
View(sa16)
library(rio)
bb14 <- import('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx')
View(bb14)
convert('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
"bb14.csv")
bb14 <- read.csv('bb14.csv')
View(bb14)
bb14 <- import('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx')
View(bb14)
bb14 <- source_Xlsx('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
2, Cache = TRUE)
bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
2, Cache = TRUE)
# install.packages("xlsx")
install.packages("xlsx")
library(xlsx)
bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
2, Cache = TRUE)
View(bb14)
bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
2, cache = TRUE)
View(bb14)
bb14 <- source_XlsxData('https://www.statistik-berlin-brandenburg.de/Publikationen/Dowmies/BB_LT_2014_Wahlkreise_Endg_Ergebnis.xlsx',
2, cache = TRUE)
URL <- "www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
# Create a temporary file called 'temp' to put the zip file into
temp <- tempfile()
# Download the compressed file into the temporary file
download.file(URL, temp)
# Decompress the file and convert it into a data frame
he13 <- read.csv(gzfile(temp, "he13.csv"))
# Delete the temporary file
unlink(temp)
# Store the URL in an object called 'URL'
URL <- "www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
# Create a temporary file called 'temp' to put the zip file into
temp <- tempfile()
# Download the compressed file into the temporary file
download.file(URL, temp)
# Decompress the file and convert it into a data frame
he13 <- source_XlsxData(gzfile(temp, "landtagswahl2013.xls"))
# Delete the temporary file
unlink(temp)
URL <- "www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
temp <- tempfile()
download.file(URL, temp)
URL <- "http://www.statistik-hessen.de/fileadmin/media/fb05/dokumente/landtagswahl2013.zip"
temp <- tempfile()
download.file(URL, temp)
he13 <- source_XlsxData(gzfile(temp, "landtagswahl2013.xls"))
he13 <- import(gzfile(temp, "landtagswahl2013.xls"))
