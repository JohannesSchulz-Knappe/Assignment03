main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = reorder(states, -Murder),
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
barplot(USArrests$murder,
names.arg = states,
las = 2,
ylab = "Murder rate per 100,000 in different states",
main = "Murder rate in the United States in 1973")
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States'
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)',
ylab = 'Number of States')
hist(USArrests$assault,
main = 'Violent Assault by USA States (per 100,000) in 1973',
xlab = 'numeric	 Assault arrests (per 100,000)')
library(dplyr)
library(rvest)
install.packages('rvest')
library(rvest)
URL <- http://www.bbc.com/sport/winter-olympics/2014/medals/countries
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
# Get and parse expenses_table from the webpage
MedalTable <- URL %>% read_html() %>%
html_nodes('#medals-table') %>%
html_table() %>%
as.data.frame
View(MedalTable)
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
rm(list = ls())
library(dplyr)
library(rvest)
URL <- 'http://www.bbc.com/sport/winter-olympics/2014/medals/countries'
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table') %>%
html_table() %>%
as.data.frame
html_nodes('#medals__table') %>%
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals_table__table') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#orb-nav-links') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#medals-table__total--silver') %>%
html_table() %>%
as.data.frame
MedalsTable <- URL %>% read_html() %>%
html_nodes('#table') %>%
html_table() %>%
as.data.frame
# Get and parse expenses_table from the webpage
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
View(MedalsTable)
head(MedalsTable)
drop(NA.$MedalsTable)
drop(MedalsTable$NA.)
head(MedalsTable)
MedalsTable$NA. <- NULL
head(MedalsTable)
MedalsTable <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table() %>%
as.data.frame
head(MedalsTable)
View(MedalsTable)
MedalsTable$NA. <- NULL
View(MedalsTable)
TotalMedals <- arrange(MedalsTable, desc(Total))
head(TotalMedals)
tables <- URL %>% read_html() %>%
html_nodes('table') %>%
html_table()
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment02',
'C:/Users/User/Documents/GitHub/Assignment02')
toBibtex(citation())
# Saxony Anhalt 2016
sa16 <- read.csv('http://www.statistik.sachsen-anhalt.de/wahlen/lt16/erg/csv/lt16dat2.csv',
sep = ';')
View(sa16)
rp16 <- read.csv('Data_Files/wahlnachtanalyse-lw2016_page_65.csv', header = FALSE, sep = ';')
trees <- c('Jomon Sugi', 'Huon Pine')
View(trees)
str_split_fixed(trees, pattern = ' ', n = 2)
library(stringr)
str_split_fixed(trees, pattern = ' ', n = 2)
View(trees)
str_split_fixed(trees, pattern = ' ', n = 2)
trees2 <- data.frame[str_split_fixed(trees, pattern = ' ', n = 2)]
trees2 <- str_split_fixed(trees, pattern = ' ', n = 2)
View(trees2)
trees <- c('1 Sugi', '2 Pine')
View(trees)
trees <- c('1 Sugi', '2 Pine')
View(trees)
trees2 <- str_split_fixed(trees, pattern = ' ', n = 2)
View(trees2)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(xlsx)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(xlsx)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
library(repmis)
library(rio)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
View(rp16)
rp16 <- source_XlsxData('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = xlsx,
2, cache = TRUE)
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
2, cache = TRUE)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
2)
View(rp16)
rp16 <- import('http://www.wahlen.rlp.de/ltw/wahlen/2016_Landtagswahlergebnisse_Wahlkreise_Endgueltig.xlsx', format = 'xlsx',
sheetIndex = 2)
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 27 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creationg
## if not done before, install if necessary:
# install.packages
# load packages
library(repmis)
library(rvest)
library(dplyr)
library(rio)
library(xlsx)
library(plyr)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, edu, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, refugee, "ID")
View(Data)
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Creating the Dataset
# Johannes Schulz-Knappe
# Update 27 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for dataset creationg
## if not done before, install if necessary:
# install.packages
# load packages
library(repmis)
library(rvest)
library(plyr)
library(dplyr)
library(rio)
library(xlsx)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
#-----------------------------------------#
# 2. Run gathering and cleaning R files   #
#-----------------------------------------#
# Dynamically run R files in this order
## 2.1 Electoral data gathering
source("data_gathering/election_data_gathering.R")
## 2.2 Structural data gathering
source("data_gathering/structural_data_gathering.R")
## 2.3 Electoral data cleaning
source("data_cleaning/election_data_cleaning.R")
## 2.4 Structural data cleaning
source("data_cleaning/structural_data_cleaning.R")
#-----------------------------------------#
# 3. Merge the data                       #
#-----------------------------------------#
# Merge the data into the final data frame
Data <- merge(data.election, edu, "ID")
Data <- merge(Data, gdp, "ID")
Data <- merge(Data, unemp, "ID")
Data <- merge(Data, refugee, "ID")
View(Data)
rm(bw_raw)
rm(rp11_raw)
rm(rp16_raw)
rm(sa11_raw)
rm(sa16_raw)
rm(data.election)
rm(edu)
rm(gdp)
rm(unemp)
rm(refugee)
rm(list = ls())
#######################################################################
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
# Assignment03
# Analysis
# Md Mujahedul Islam
# Update 27 April 2016
# Hertie School of Governance
#######################################################################
#-----------------------------------------#
# 1. Prepare the workspace                #
#-----------------------------------------#
## 1.1 Clear the environment
rm(list = ls())
## 1.2 Load packages for data analysis
## if not done before, install if necessary:
# install.packages("plyr", "dplyr", "xtable", "texreg", "stargazer",
#                  "magrittr", "readstata13", "ggplot2", "reshape")
# Load packages
# Shortcut to load packages I need
load <- c("plyr", "dplyr", "xtable", "texreg", "stargazer", "magrittr", "readstata13",
"ggplot2", "reshape")
loaded <- lapply(load, require, character.only = TRUE)
rm(load, loaded)
## 1.3 Set the working directory
# Create list of commonly used working directories (update, if needed)
possible_dir <- c('C:/Users/Johannes SK/Dropbox/Studium/Spring2016/CollaborativeResearch/Assignment03',
'C:/Users/User/Documents/GitHub/Assignment03')
# Set to first valid directory in the possible_dir vector
set_valid_wd(possible_dir)
# remove possible_dir vector
rm(possible_dir)
## 1.4 Create and load the dataset
source('1_Data.R')
#--------------------------------------#
# 2. Descriptive Statistics            #
#--------------------------------------#
## 2.1 Mean values
# Create mean values for variables
mean(Data$vote.AfD, na.rm = TRUE)
mean(Data$GDP.capita, na.rm = TRUE)
mean(Data$unempl.rate, na.rm = TRUE)
mean(Data$nodegree.ratio, na.rm = TRUE)
mean(Data$n.refugees, na.rm = TRUE)
mean(Data$abitur.ratio, na.rm = TRUE)
# Loop function for finding "mean" for all the variables
for (i in 4:length(names(Data))) {
Data[, i] %>%
mean() %>%
round(digits = 2) %>%
paste(names(Data)[i], ., '\n') %>% # the . directs the
cat()
}
## 2.2 Summary statistics of all variables
# Assign variable labels
summary_labels <- c('Vote share of AfD', 'Vote turnout in 2011',
'Vote share of CDU in 2011', 'Vote share of Greens in 2011',
'Vote share of SPD in 2011', 'Vote share of FDP in 2011',
'Vote share of Linke in 2011', 'High school ratio',
'No high school degree', 'GDP per capita',
'Unemployment rate', 'No. of refugees')
# Create summary statistics table
stargazer(Data[4:16],
title = 'Summary statistics of all variables',
covariate.labels = summary_labels,
font.size = 'small',
digit = 2,
out = 'outputs/tables/summary_statistics.tex')
## 2.3 Histograph using ggplot to show the number of refugees
ggplot(Data) +
geom_histogram(aes(x = n.refugees),
colour = "black",
fill = "transparent",
binwidth = 30) +
ylab("Frequency") +
xlab("No. of refugess in RP, BW, and SA") +
theme_light()
## 2.4 AfD vote share by district
ggplot(Data) +
geom_bar(aes(y = vote.AfD, x = reorder(district.name, -vote.AfD)),
stat = "identity") +
ylab("AfD vote share") +
xlab("Districts of RP, BW and SA") +
ggtitle("Vote share of AfD in three different states of Germany") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
out = 'outputs/figures/AfD_voteshare_in_RP_BW_SA.pdf'
## 2.5 Correlation matrix in table format
correlation.matrix <- cor(Data[, c("vote.AfD","lag.CDU",
"lag.SPD","GDP.capita",
"unempl.rate","n.refugees",
"abitur.ratio")])
stargazer(correlation.matrix,
title = "Correlation Matrix",
font.size = 'small',
out = 'outputs/tables/correlation_matrix.tex')
#--------------------------------------#
# 3. Initial correlation analysis      #
#--------------------------------------#
## 3.1 Correlation of AfD's vote share and unemployment rate
# The result shows statistically significant positve
# correlation of increase in unemployment rate with
# the increase in AfD vote share in the three states
ggplot2::ggplot(Data, aes(log(x = unempl.rate), vote.AfD)) +
xlab("Unemployment rate in RP, BW, and SA") +
ylab("AfD vote share (in %)") +
geom_point() + geom_smooth() +
theme_bw()
# Test for statistical significance of above correlation
cor.test(log(Data$vote.AfD), Data$unempl.rate)
## 3.2 Correlation of AfD vote share and GDP per capita
# The result shows statistically significant negative
# coorelation of increase in Per capita GDP
# with AfD vote share
ggplot2::ggplot(Data,aes(log(x = GDP.capita), vote.AfD)) +
xlab("GDP per capita in RP, BW, and SA") +
ylab("AfD vote share (in %)") +
geom_point() + geom_smooth() +
theme_bw()
# Test for statistical significance of above correlation
cor.test(log(Data$vote.AfD), Data$GDP.capita)
## 3.3 Correlation of AfD vote share and No. of Refugees
# The result shows positive coorelation of
# increase no. of refugees with with AfD's vote share,
# though it is not statistically significant (most likely
# due to outdated refugee numbers)
ggplot2::ggplot(Data,aes(log(x = n.refugees), vote.AfD)) +
xlab("Number of refugees in RP, BW, and SA") +
ylab("AfD's vote share (in %)") +
geom_point() + geom_smooth() +
theme_light()
# Test for statistical significance of above correlation
cor.test(log(Data$vote.AfD), Data$n.refugees)
#--------------------------------------#
# 4. Inferential Analysis              #
#--------------------------------------#
# Create series of regression models
reg1 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees, data = Data)
reg2 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees + lag.CDU +
lag.SPD + lag.turnout, data = Data)
reg3 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees +
abitur.ratio + nodegree.ratio, data = Data)
reg4 <- lm(vote.AfD ~ GDP.capita + unempl.rate + n.refugees
+ lag.CDU + lag.SPD + lag.turnout + abitur.ratio +
nodegree.ratio, data = Data)
# Assign variable labels
var_labels <- c('GDP per capita', 'Unemployment rate', 'No. of Refugees',
'Vote share of CDU in 2011 election',
'Vote share of SPD in 2011 election',
'High School Ratio', 'University Degree ratio', '(Intercept)')
# Create regression table
stargazer::stargazer(reg1, reg2, reg3, reg4,
omit = 'as.factor*',
omit.stat = c('f', 'ser'), # to nicely fits on the page
out.header = F,
title = 'Determinants of the vote share of the Alternative for Germany',
dep.var.labels = 'Vote share of AfD',
covariate.labels = var_labels,
label = 'AfD_voteshare',
add.lines = list(c('District FE?', rep('NO', 4))),
font.size = 'small',
digit = 2,
out = 'outputs/tables/afd_voteshare_regressions.tex')
install.packages("texreg")
ggplot(Data) +
geom_histogram(aes(x = n.refugees),
colour = "black",
fill = "transparent",
binwidth = 30) +
ylab("Frequency") +
xlab("No. of refugess in RP, BW, and SA") +
theme_light()
ggplot(Data) +
geom_histogram(aes(x = n.refugees),
colour = "black",
fill = "transparent",
binwidth = 30) +
ylab("Frequency") +
xlab("No. of refugess in RP, BW, and SA") +
theme_light() +
out = 'outputs/figures/frequency_of_refugees.png'
ggplot(Data, out = 'outputs/figures/frequency_of_refugees.png') +
geom_histogram(aes(x = n.refugees),
colour = "black",
fill = "transparent",
binwidth = 30) +
ylab("Frequency") +
xlab("No. of refugess in RP, BW, and SA") +
theme_light()
ggplot(Data, out = 'outputs/figures/frequency_of_refugees.png') +
geom_histogram(aes(x = n.refugees),
colour = "black",
fill = "transparent",
binwidth = 30) +
ylab("Frequency") +
xlab("No. of refugees in RP, BW, and SA") +
theme_light()
ggplot(Data) +
geom_histogram(aes(x = n.refugees),
colour = "black",
fill = "transparent",
binwidth = 30) +
ylab("Frequency") +
xlab("No. of refugees in RP, BW, and SA") +
theme_light()
ggplot(Data) +
geom_bar(aes(y = vote.AfD, x = reorder(district.name, -vote.AfD)),
stat = "identity") +
ylab("AfD vote share") +
xlab("Districts of RP, BW and SA") +
ggtitle("Vote share of AfD in three different states of Germany") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
out = 'outputs/figures/AfD_voteshare_in_RP_BW_SA.pdf'
ggplot(Data) +
geom_bar(aes(y = vote.AfD, x = reorder(district.name, -vote.AfD)),
stat = "identity") +
ylab("AfD vote share") +
xlab("Districts of RP, BW and SA") +
ggtitle("Vote share of AfD in districts of BW, RP, and SA") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
out = 'outputs/figures/AfD_voteshare_in_RP_BW_SA.pdf'
ggplot(Data) +
geom_bar(aes(y = vote.AfD, x = reorder(district.name, -vote.AfD)),
stat = "identity") +
ylab("AfD vote share") +
xlab("Districts of BW, RP, and SA") +
ggtitle("Vote share of AfD in districts of BW, RP, and SA") +
theme_bw() +
theme(axis.text.x = element_text(angle = 90))
out = 'outputs/figures/AfD_voteshare_in_RP_BW_SA.pdf'
